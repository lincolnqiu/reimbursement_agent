'''
trip_sheet_parser.py
===================
è¯¥æ–‡ä»¶ä¸“é—¨è´Ÿè´£è§£æå­˜æ”¾äº `trip_sheets/` ç›®å½•ä¸­çš„ *è¡Œç¨‹å•ï¼ˆTrip Sheetï¼‰* PDFï¼Œ
å¹¶å°†ä»¥ä¸‹ç»“æ„åŒ–ä¿¡æ¯ä¿å­˜ä¸º JSONï¼š
1. `total_amount`ï¼šè¡Œç¨‹å•åˆè®¡é‡‘é¢ï¼ˆæµ®ç‚¹æ•°ï¼‰ã€‚
2. `trips`ï¼šåˆ—è¡¨ï¼Œæ¯ä¸€é¡¹åŒ…å«ï¼š
   â€¢ `date` ä¸Šè½¦æ—¥æœŸï¼Œæ ¼å¼ `yyyy/mm/dd`ã€‚
   â€¢ `origin` èµ·ç‚¹å­—ç¬¦ä¸²ã€‚
   â€¢ `destination` ç»ˆç‚¹å­—ç¬¦ä¸²ã€‚
   â€¢ `amount` è¯¥è¡Œç¨‹é‡‘é¢ï¼ˆæµ®ç‚¹æ•°ï¼‰ã€‚

å…¸å‹ä½¿ç”¨åœºæ™¯ï¼šä¸»æµç¨‹ (`src/main.py`) å·²å°†æ£€æµ‹åˆ°çš„è¡Œç¨‹å• PDF å¤åˆ¶åˆ° `trip_sheets/` ç›®å½•ï¼Œ
è‹¥éœ€è¦è¿›ä¸€æ­¥è§£æè¡Œç¨‹å•è¡¨æ ¼å¹¶ç”ŸæˆæŠ¥è¡¨ï¼Œå¯ç›´æ¥è°ƒç”¨æœ¬è„šæœ¬ï¼š

```bash
python src/trip_sheet_parser.py            # è§£æå…¨éƒ¨è¡Œç¨‹å•å¹¶è¾“å‡º JSON
python src/trip_sheet_parser.py foo.pdf    # ä»…è§£ææŒ‡å®šæ–‡ä»¶
```

æ›´æ–°æ¡ä»¶ï¼š
- è¡Œç¨‹å•ç‰ˆå¼æˆ–è¡¨å¤´å‘ç”Ÿå˜åŒ–å¯¼è‡´è¡¨æ ¼åˆ—ç´¢å¼•å˜åŠ¨æ—¶ï¼Œéœ€è¦è°ƒæ•´ `_extract_trips_from_table` ä¸­çš„åˆ—æ˜ å°„ã€‚
- éœ€è¦æå–æ›´å¤šå­—æ®µï¼ˆå¦‚è½¦å‹ã€é‡Œç¨‹ç­‰ï¼‰æ—¶ï¼Œæ‰©å±• `_extract_trips_from_table` çš„è¿”å›å€¼ã€‚
'''

import os
import json
import re
from typing import List, Dict, Any, Optional

import pdfplumber

from config import TRIP_SHEETS_DIR, OUTPUT_DIR

# ---------- æ­£åˆ™ ---------- #
_TOTAL_AMOUNT_REGEX = re.compile(r"åˆè®¡\s*([0-9]+(?:\.[0-9]{1,2})?)\s*å…ƒ")
_YEAR_IN_RANGE_REGEX = re.compile(r"è¡Œç¨‹èµ·æ­¢æ—¥æœŸ[:ï¼š]\s*([0-9]{4})-")
_DATE_PART_REGEX = re.compile(r"(\d{2})-(\d{2})")
_AMOUNT_REGEX_SIMPLE = re.compile(r"[0-9]+(?:\.[0-9]{1,2})?")


# ---------- å†…éƒ¨å¸®åŠ©å‡½æ•° ---------- #

def _extract_year(full_text: str) -> str:
    """ä»æ•´é¡µæ–‡æœ¬ä¸­æå–è¡Œç¨‹å¹´ä»½ï¼Œé»˜è®¤å½“å‰å¹´ä»½ã€‚"""
    m = _YEAR_IN_RANGE_REGEX.search(full_text)
    if m:
        return m.group(1)
    # å…œåº•ï¼šä½¿ç”¨å½“å‰å¹´ä»½
    from datetime import datetime
    return str(datetime.now().year)


def _standardize_date(date_part: str, year: str) -> Optional[str]:
    """å°†å¦‚ '04-11' è½¬æˆ 'YYYY/MM/DD'ã€‚è‹¥åŒ¹é…å¤±è´¥è¿”å› Noneã€‚"""
    m = _DATE_PART_REGEX.match(date_part)
    if not m:
        return None
    month, day = m.groups()
    return f"{year}/{month}/{day}"


def _extract_trips_from_table(table: List[List[str]], year: str) -> List[Dict[str, Any]]:
    """æ ¹æ®å·²è¯†åˆ«çš„è¡Œç¨‹è¡¨æ ¼ï¼ˆå«è¡¨å¤´ï¼‰æå– trips åˆ—è¡¨ã€‚"""
    trips: List[Dict[str, Any]] = []

    # å…ˆç¡®å®šè¡¨å¤´æ‰€åœ¨è¡Œï¼ˆå«ã€ä¸Šè½¦æ—¶é—´ã€å…³é”®è¯ï¼‰
    header_idx = None
    for idx, row in enumerate(table):
        if row and any("ä¸Šè½¦æ—¶é—´" in (cell or "") for cell in row):
            header_idx = idx
            break
    if header_idx is None:
        # æœªæ‰¾åˆ°è¡¨å¤´
        return trips

    # ---------- åŠ¨æ€ç¡®å®šåˆ—ç´¢å¼• ---------- #
    header_row = table[header_idx]

    def _find_col(keyword: str) -> Optional[int]:
        for i, cell in enumerate(header_row):
            if cell and keyword in cell:
                return i
        return None

    DATE_COL = _find_col("ä¸Šè½¦æ—¶é—´") or 2  # å›é€€é»˜è®¤
    ORIGIN_COL = _find_col("èµ·ç‚¹") or 5
    DEST_COL = _find_col("ç»ˆç‚¹") or (ORIGIN_COL + 1)
    AMOUNT_COL = _find_col("é‡‘é¢")
    if AMOUNT_COL is None:
        # å…œåº•ï¼šå°è¯•åœ¨ header ä¸­åŒ…å« 'é‡‘é¢[' æˆ– '[' å­—ç¬¦çš„åˆ—
        AMOUNT_COL = next((i for i, c in enumerate(header_row) if c and "é‡‘é¢" in c), 8)

    for row in table[header_idx + 1:]:
        if not row or not row[0]:  # è·³è¿‡ç©ºè¡Œ
            continue
        # å°è¯•è¡Œå·æ˜¯æ•°å­—æ¥åˆ¤æ–­æœ‰æ•ˆè¡Œ
        try:
            int(str(row[0]).strip())
        except ValueError:
            continue

        # --- æ—¥æœŸ --- #
        date_raw = (row[DATE_COL] or "").strip() if len(row) > DATE_COL else ""
        date_std = _standardize_date(date_raw.split()[0] if date_raw else "", year)
        if not date_std:
            # è‹¥æ—¥æœŸæ— æ³•è§£æï¼Œè·³è¿‡è¯¥è¡Œ
            continue

        # --- èµ·ç‚¹ / ç»ˆç‚¹ --- #
        origin = (row[ORIGIN_COL] or "").strip() if len(row) > ORIGIN_COL else ""
        destination = (row[DEST_COL] or "").strip() if len(row) > DEST_COL else ""

        # --- é‡‘é¢ --- #
        amount_raw = (row[AMOUNT_COL] or "") if len(row) > AMOUNT_COL else ""
        # å»æ‰è¯¸å¦‚ 'å…ƒ'ã€'ï¿¥'ã€'Â¥' ç­‰ç¬¦å·
        amount_raw_clean = re.sub(r"[å…ƒÂ¥ï¿¥,]", "", amount_raw)
        amt_match = _AMOUNT_REGEX_SIMPLE.search(amount_raw_clean)
        amount_val: Optional[float] = float(amt_match.group()) if amt_match else None

        if not origin and not destination and amount_val is None:
            # å¯èƒ½æ˜¯è¡¨æ ¼å°¾éƒ¨ç©ºè¡Œ
            continue

        trips.append({
            "date": date_std,
            "origin": origin,
            "destination": destination,
            "amount": amount_val,
        })

    return trips


# ---------- æ ¸å¿ƒè§£æå‡½æ•° ---------- #

def parse_trip_sheet_pdf(pdf_path: str) -> Dict[str, Any]:
    """è§£æå•ä¸ª Trip Sheet PDFï¼Œè¿”å›åŒ…å«åˆè®¡é‡‘é¢ä¸ trips åˆ—è¡¨çš„ dictã€‚"""
    result: Dict[str, Any] = {
        "file_name": os.path.basename(pdf_path),
        "total_amount": None,
        "trips": [],
    }

    try:
        with pdfplumber.open(pdf_path) as pdf:
            # â€”â€” å…ˆæ•´ä½“æ–‡æœ¬ï¼Œç”¨äºæŠ“æ€»é‡‘é¢ & å¹´ä»½ â€”â€”
            full_text = "".join(page.extract_text() or "" for page in pdf.pages)

            # åˆè®¡é‡‘é¢
            amount_match = _TOTAL_AMOUNT_REGEX.search(full_text)
            if amount_match:
                result["total_amount"] = float(amount_match.group(1))

            # å¹´ä»½ï¼Œç”¨äºæ ¼å¼åŒ–æ—¥æœŸ
            year = _extract_year(full_text)

            # â€”â€” éå†è¡¨æ ¼ â€”â€”
            for page in pdf.pages:
                tables = page.extract_tables() or []
                for table in tables:
                    trips_from_table = _extract_trips_from_table(table, year)
                    if trips_from_table:
                        result["trips"].extend(trips_from_table)
    except Exception as e:
        print(f"âŒ è§£æè¡Œç¨‹å• {os.path.basename(pdf_path)} å¤±è´¥: {e}")

    return result


# ---------- CLI å…¥å£ ---------- #

def main():
    """éå† trip_sheets/ ç›®å½•ï¼Œè§£ææ‰€æœ‰ PDF å¹¶ä¿å­˜ JSONã€‚"""
    import argparse
    parser = argparse.ArgumentParser(description="è§£æ trip_sheets ç›®å½•ä¸­çš„è¡Œç¨‹å• PDFï¼Œå¹¶ç”Ÿæˆ JSON æ•°æ®ã€‚")
    parser.add_argument("pdf", nargs="?", help="å¯é€‰ï¼šä»…è§£ææŒ‡å®šçš„ PDF æ–‡ä»¶ã€‚è·¯å¾„å¯ä»¥æ˜¯ç»å¯¹æˆ–ç›¸å¯¹ã€‚")
    args = parser.parse_args()

    # â€”â€” å‡†å¤‡ç›®æ ‡æ–‡ä»¶åˆ—è¡¨ â€”â€”
    if args.pdf:
        target_files = [args.pdf] if os.path.isfile(args.pdf) else []
        if not target_files:
            print(f"âš ï¸ æŒ‡å®šçš„æ–‡ä»¶ä¸å­˜åœ¨ï¼š{args.pdf}")
            return
    else:
        if not os.path.isdir(TRIP_SHEETS_DIR):
            print(f"âš ï¸ æœªæ‰¾åˆ°ç›®å½• {TRIP_SHEETS_DIR}ï¼Œè¯·å…ˆè¿è¡Œä¸»æµç¨‹è¯†åˆ«å¹¶åˆ†æµè¡Œç¨‹å•ã€‚")
            return
        target_files = [os.path.join(TRIP_SHEETS_DIR, f) for f in os.listdir(TRIP_SHEETS_DIR) if f.lower().endswith(".pdf")]
        if not target_files:
            print(f"ğŸ“‚ {TRIP_SHEETS_DIR} ç›®å½•ä¸ºç©ºï¼Œæ²¡æœ‰å¯è§£æçš„ PDFã€‚")
            return

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    for pdf_path in target_files:
        base_name = os.path.basename(pdf_path)
        print(f"ğŸšŒ æ­£åœ¨è§£æè¡Œç¨‹å•: {base_name}")
        parsed_result = parse_trip_sheet_pdf(pdf_path)

        json_name = os.path.splitext(base_name)[0] + ".json"
        json_path = os.path.join(OUTPUT_DIR, json_name)

        try:
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(parsed_result, f, ensure_ascii=False, indent=4)
            print(f"ğŸ’¾ è¡Œç¨‹å•æ•°æ®å·²ä¿å­˜è‡³: {json_path}")
        except IOError as e:
            print(f"âŒ ä¿å­˜ JSON å¤±è´¥ ({json_name}): {e}")


if __name__ == "__main__":
    main() 