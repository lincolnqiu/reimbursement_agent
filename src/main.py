"""
reimbursement_tool.py
=====================
è¯¥è„šæœ¬æ˜¯å‘ç¥¨æ‰¹é‡å¤„ç†å’ŒæŠ¥é”€è¾…åŠ©å·¥å…·çš„ä¸»å…¥å£ç‚¹ã€‚å®ƒåè°ƒä»¥ä¸‹æ“ä½œï¼š
1.  ä» `input/` ç›®å½•è¯»å– PDF å‘ç¥¨æ–‡ä»¶ã€‚
2.  è°ƒç”¨ `extraction` æ¨¡å—è§£ææ¯å¼ å‘ç¥¨ï¼Œæå–å…³é”®ä¿¡æ¯ï¼ˆå‘ç¥¨ç±»å‹ã€é‡‘é¢ã€ç±»åˆ«ã€å‘ç¥¨å·ç ï¼‰ï¼Œ
    è¯¥æ¨¡å—ä¼šé¦–å…ˆå°è¯• `pdfplumber`ï¼Œå¦‚æœç»“æœä¸å®Œæ•´åˆ™ä½¿ç”¨ LLM OCR è¿›è¡Œå…œåº•ã€‚
3.  è°ƒç”¨ `file_utils` æ¨¡å—å¤„ç†æ–‡ä»¶ï¼š
    - æ ¹æ®å‘ç¥¨å·ç è¿›è¡Œå»é‡ï¼Œå¹¶å°†é‡å¤æ–‡ä»¶ç§»è‡³ `duplicates/` ç›®å½•ã€‚
    - å°†å·²æˆåŠŸå¤„ç†çš„ PDF é‡å‘½åå¹¶ä¿å­˜åˆ° `output/` ç›®å½•ã€‚
4.  å°†æ‰€æœ‰æå–åˆ°çš„ã€éé‡å¤çš„å‘ç¥¨ä¿¡æ¯ä¿å­˜ä¸º `output/invoice_data.json` æ–‡ä»¶ï¼Œä»¥ä¾¿åç»­äººå·¥æˆ–è„šæœ¬è¿›ä¸€æ­¥å¤„ç†ã€‚
5.  æ”¯æŒé€šè¿‡å‘½ä»¤è¡Œå‚æ•° `--stage` è¿›è¡Œåˆ†é˜¶æ®µæµ‹è¯•ã€‚

æ›´æ–°æ¡ä»¶ï¼š
- å½“ä¸»å¤„ç†æµç¨‹æˆ–å‘½ä»¤è¡Œå‚æ•°éœ€è¦è°ƒæ•´æ—¶ï¼Œæ›´æ–°æ­¤æ–‡ä»¶ã€‚
- å½“éœ€è¦å¼•å…¥æ–°çš„å¤„ç†æ¨¡å—æˆ–æ›´æ”¹ç°æœ‰æ¨¡å—çš„è°ƒç”¨æ–¹å¼æ—¶ï¼Œæ›´æ–°æ­¤æ–‡ä»¶ã€‚
"""

import os
# import shutil # åŠŸèƒ½å·²ç§»è‡³ file_utils.py
from typing import Dict, List, Optional # Optional å¯èƒ½ä»éœ€ï¼ŒList å’Œ Dict è‚¯å®šéœ€è¦
import argparse
from collections import defaultdict
import json # <-- æ–°å¢å¯¼å…¥
import asyncio  # æ–°å¢ï¼šç”¨äºå¹¶å‘è§£æ
import shutil  # æ–°å¢ï¼šåœ¨åç»­é˜¶æ®µä»…å¤åˆ¶æ–‡ä»¶ï¼Œä¸å†äºŒæ¬¡é‡å‘½å
import uuid    # æ–°å¢ï¼šç”Ÿæˆå…¨å±€å”¯ä¸€æ–‡ä»¶åï¼ˆUUIDï¼‰

# # +++++ æ–°å¢å¯¼å…¥ +++++ # å·²ç§»è‡³ extraction.py
# import base64
# from io import BytesIO
# from openai import OpenAI
# from pydantic import BaseModel, Field
# from dotenv import load_dotenv
# from pdf2image import convert_from_path, exceptions as pdf2image_exceptions
# # ----- ç»“æŸæ–°å¢å¯¼å…¥ -----

# +++++ ä» config.py å¯¼å…¥é…ç½® +++++
from config import INPUT_DIR, OUTPUT_DIR, DUPLICATES_DIR, TRIP_SHEETS_DIR  # FIELDS å’Œ REGEX_PATTERNS ç”± extraction.py ä½¿ç”¨
# ----- ç»“æŸå¯¼å…¥é…ç½® -----

# +++++ ä» extraction.py å¯¼å…¥åŠŸèƒ½ +++++
from extraction import parse_invoice, extract_with_pdfplumber # LLMInvoiceOutput, get_openai_client, call_llm_ocr æ˜¯å†…éƒ¨å®ç°ç»†èŠ‚
# ----- ç»“æŸå¯¼å…¥ ----

# +++++ ä» excel_utils.py å¯¼å…¥åŠŸèƒ½ +++++
# NOTE: Excel ç”Ÿæˆé€»è¾‘å·²ç§»é™¤ï¼Œå¦‚éœ€æŠ¥è¡¨è¯·ä½¿ç”¨å•ç‹¬è„šæœ¬å¤„ç†ã€‚
# ----- ç»“æŸå¯¼å…¥ -----

# +++++ ä» file_utils.py å¯¼å…¥åŠŸèƒ½ +++++
from file_utils import handle_duplicate_invoice
# ----- ç»“æŸå¯¼å…¥ -----

# +++++ å¼•å…¥ Trip Sheet è§£æå‡½æ•° +++++
from trip_sheet_parser import parse_trip_sheet_pdf


# -------- ä¸»æµç¨‹ -------- #

def main():
    # ---------- CLI è§£æ ---------- #
    parser = argparse.ArgumentParser(description="ä¸­å›½å‘ç¥¨æ‰¹é‡å¤„ç† / æŠ¥é”€è¾…åŠ©è„šæœ¬")
    parser.add_argument(
        "--stage",
        choices=["pdfplumber", "llm", "rename", "json"],
        default="json",
        help="åˆ†é˜¶æ®µæµ‹è¯•ï¼špdfplumber=ä»…æ–‡æœ¬è§£æï¼›llm=è§£æ+LLMå…œåº•ï¼›rename=é‡å‘½åå¹¶æŸ¥é‡ï¼›json=å®Œæ•´æµç¨‹ï¼ˆä¿å­˜ JSONï¼‰"
    )
    args = parser.parse_args()

    os.makedirs(INPUT_DIR, exist_ok=True)
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(DUPLICATES_DIR, exist_ok=True)
    os.makedirs(TRIP_SHEETS_DIR, exist_ok=True)

    pdf_files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(".pdf")]
    if not pdf_files:
        print("ğŸ“‚ æœªæ‰¾åˆ°ä»»ä½• PDF å‘ç¥¨ï¼Œè¯·å°†æ–‡ä»¶æ”¾å…¥ input/ ç›®å½•åå†è¿è¡Œã€‚")
        return

    # ---------- é¦–è½®ç»Ÿä¸€é‡å‘½å â†’ UUID ---------- #
    renamed_files = []
    for original_name in pdf_files:
        original_path = os.path.join(INPUT_DIR, original_name)

        # ç”Ÿæˆå”¯ä¸€ UUID æ–‡ä»¶åï¼Œé¿å…æç«¯æƒ…å†µä¸‹çš„å†²çª
        while True:
            uuid_str = uuid.uuid4().hex  # æ— è¿å­—ç¬¦ï¼Œæ›´ç²¾ç®€
            new_name = f"{uuid_str}.pdf"
            new_path = os.path.join(INPUT_DIR, new_name)
            if not os.path.exists(new_path):
                break  # ç¡®ä¿æ–‡ä»¶åå”¯ä¸€

        try:
            os.rename(original_path, new_path)
            # print(f"ğŸ”„ é‡å‘½å: {original_name} â†’ {new_name}")
            renamed_files.append(new_name)
        except OSError as e:
            print(f"âŒ é‡å‘½å {original_name} å¤±è´¥: {e}")

    # åç»­æµç¨‹ç»Ÿä¸€ä½¿ç”¨é‡å‘½ååçš„æ–‡ä»¶åˆ—è¡¨
    pdf_files = renamed_files

    seen_numbers = set()
    parsed_rows: List[Dict[str, str]] = []  # å‘ç¥¨è§£æç»“æœ
    trip_sheet_paths: List[str] = []        # å¾…è§£æçš„è¡Œç¨‹å• PDF è·¯å¾„
    seq_counter = 1  # åºå·è®¡æ•°å™¨ï¼ˆç”¨äºé‡å‘½åï¼‰

    async def run_parsing():
        """å¹¶å‘è§£æ PDFï¼Œè¿”å›è§£æç»“æœåˆ—è¡¨ï¼ˆé¡ºåºä¸ pdf_files ä¿æŒä¸€è‡´ï¼‰ã€‚"""
        tasks = []
        for pdf_path in [os.path.join(INPUT_DIR, f) for f in pdf_files]:
            if args.stage == "pdfplumber":
                tasks.append(asyncio.to_thread(extract_with_pdfplumber, pdf_path))
            else:
                from extraction import parse_invoice_async  # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯
                tasks.append(parse_invoice_async(pdf_path))
        return await asyncio.gather(*tasks, return_exceptions=True)

    # åŒæ­¥å‡½æ•° main() é‡Œå¯åŠ¨å¼‚æ­¥è§£æ
    parsed_results = asyncio.run(run_parsing())

    # ---------- å¤„ç†è§£æç»“æœ ---------- #
    for pdf_name, result in zip(pdf_files, parsed_results):
        if isinstance(result, Exception):
            print(f"âŒ è§£æ {pdf_name} æ—¶æŠ›å‡ºå¼‚å¸¸: {result}")
            continue

        info = result

        if args.stage == "pdfplumber":
            # ===== è¡Œç¨‹å•åˆ†æµ =====
            if info.get("is_trip_sheet"):
                dest_path = os.path.join(TRIP_SHEETS_DIR, pdf_name)
                try:
                    shutil.copy2(os.path.join(INPUT_DIR, pdf_name), dest_path)
                    print(f"ğŸš• è¡Œç¨‹å•å·²è¯†åˆ«å¹¶å¤åˆ¶è‡³ {TRIP_SHEETS_DIR}: {pdf_name}")
                except Exception as e:
                    print(f"âŒ å¤åˆ¶è¡Œç¨‹å• {pdf_name} å¤±è´¥: {e}")
                continue  # è¡Œç¨‹å•ä¸å†å‚ä¸æ™®é€šå‘ç¥¨æµç¨‹

            print(f"[pdfplumber] {pdf_name} -> {info}")
            continue  # pdfplumber é˜¶æ®µåˆ°æ­¤ç»“æŸ

        if args.stage == "llm":
            print(f"[llm] {pdf_name} -> {info}")
            continue  # llm é˜¶æ®µåˆ°æ­¤ç»“æŸ

        pdf_path = os.path.join(INPUT_DIR, pdf_name)

        # ===== è¡Œç¨‹å•ç»Ÿä¸€åˆ†æµï¼ˆæ‰€æœ‰é˜¶æ®µé€‚ç”¨ï¼‰ =====
        if info.get("is_trip_sheet"):
            dest_path = os.path.join(TRIP_SHEETS_DIR, pdf_name)
            try:
                shutil.copy2(pdf_path, dest_path)
                print(f"ğŸš• è¡Œç¨‹å•å·²è¯†åˆ«å¹¶å¤åˆ¶è‡³ {TRIP_SHEETS_DIR}: {pdf_name}")
                trip_sheet_paths.append(dest_path)  # æ”¶é›†å¾…è§£æè·¯å¾„
            except Exception as e:
                print(f"âŒ å¤åˆ¶è¡Œç¨‹å• {pdf_name} å¤±è´¥: {e}")
            continue  # è¡Œç¨‹å•ä¸èµ°å¸¸è§„å‘ç¥¨æµç¨‹

        # ---------- é‡å‘½å / å»é‡ ---------- #
        invoice_number = info.get("invoice_number")
        if not invoice_number:
            print(f"âš ï¸ æ— æ³•å–å¾—å‘ç¥¨å·ç ï¼Œè·³è¿‡æ–‡ä»¶ {pdf_name}")
            continue

        if args.stage in ["rename", "json"]:
            if handle_duplicate_invoice(pdf_path, invoice_number, seen_numbers):
                continue

        if args.stage == "rename":
            # ä»…å¤åˆ¶åˆ° OUTPUT_DIRï¼Œä¿æŒ UUID æ–‡ä»¶å
            dest_name = os.path.basename(pdf_path)
            dest_path = os.path.join(OUTPUT_DIR, dest_name)
            try:
                shutil.copy2(pdf_path, dest_path)
                print(f"âœ… å·²å¤åˆ¶: {dest_name} â†’ {OUTPUT_DIR}")
            except Exception as e:
                print(f"âŒ å¤åˆ¶ {dest_name} å¤±è´¥: {e}")
            continue

        # json é˜¶æ®µï¼šå¤åˆ¶å¹¶å†™å…¥ info â†’ parsed_rows
        dest_name = os.path.basename(pdf_path)
        dest_path = os.path.join(OUTPUT_DIR, dest_name)
        try:
            shutil.copy2(pdf_path, dest_path)
        except Exception as e:
            print(f"âŒ å¤åˆ¶ {dest_name} å¤±è´¥: {e}")
            continue

        info["file_name"] = dest_name  # è®°å½• UUID æ–‡ä»¶å
        parsed_rows.append(info)
        seq_counter += 1  # ä»ä¿ç•™è®¡æ•°å™¨ï¼Œä¾›æ—¥å¿—ç­‰ç”¨é€”

    # ---------- è¡Œç¨‹å•è§£æï¼ˆå¹¶å‘ï¼‰ ---------- #
    if trip_sheet_paths:
        print(f"ğŸšŒ å³å°†è§£æ {len(trip_sheet_paths)} ä»½è¡Œç¨‹å•â€¦")

        async def run_trip_sheet_tasks():
            tasks = [asyncio.to_thread(parse_trip_sheet_pdf, p) for p in trip_sheet_paths]
            return await asyncio.gather(*tasks)

        trip_results = asyncio.run(run_trip_sheet_tasks())

        import re

        def _safe_float(s):
            try:
                return float(re.sub(r"[^0-9.]+", "", str(s)))
            except ValueError:
                return None

        for res in trip_results:
            if not res:
                continue

            base_name = os.path.splitext(res.get("file_name", "unknown.pdf"))[0] + ".json"
            json_out = os.path.join(OUTPUT_DIR, base_name)

            # â€”â€” ä¿å­˜è¡Œç¨‹å• JSON â€”â€”
            try:
                with open(json_out, "w", encoding="utf-8") as f:
                    json.dump(res, f, ensure_ascii=False, indent=4)
                print(f"ğŸ’¾ å·²ä¿å­˜è¡Œç¨‹å• JSON: {json_out}")
            except IOError as e:
                print(f"âŒ ä¿å­˜è¡Œç¨‹å• JSON å¤±è´¥ ({base_name}): {e}")

            # â€”â€” å…³è”åˆ°å‘ç¥¨ â€”â€”
            total_amt = res.get("total_amount")
            if total_amt is None:
                continue
            linked = False
            for inv in parsed_rows:
                inv_amt = _safe_float(inv.get("amount"))
                if inv_amt is None:
                    continue
                # é‡‘é¢ç›¸ç­‰ Â±0.01 ä¸”ç±»åˆ«çœ‹ä¼¼è¿è¾“æœåŠ¡ï¼ˆå¯é€‰ï¼‰
                if abs(inv_amt - total_amt) < 0.01:
                    inv["has_trip_sheet"] = True
                    inv["trip_sheet_file"] = os.path.basename(json_out)
                    linked = True
                    break
            if not linked:
                print(f"âš ï¸ æœªæ‰¾åˆ°ä¸è¡Œç¨‹å• {base_name} åŒ¹é…çš„å‘ç¥¨ï¼ˆé‡‘é¢ {total_amt}ï¼‰ã€‚")

    # ---------- æœ€ç»ˆä¿å­˜ / æ›´æ–°å‘ç¥¨ JSON ---------- #
    if parsed_rows:
        json_output_path = os.path.join(OUTPUT_DIR, "invoice_data.json")
        try:
            with open(json_output_path, "w", encoding="utf-8") as f:
                json.dump(parsed_rows, f, ensure_ascii=False, indent=4)
            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° JSON æ–‡ä»¶: {json_output_path}")
        except IOError as e:
            print(f"âŒ ä¿å­˜ JSON æ–‡ä»¶å¤±è´¥: {e}")
    else:
        if args.stage == "json":
            print("âš ï¸ æ²¡æœ‰å¯ä¿å­˜åˆ° JSON çš„å‘ç¥¨æ•°æ®ï¼")


if __name__ == "__main__":
    import time
    
    start_time = time.time()
    try:
        main()
    finally:
        end_time = time.time()
        print(f"âœ… ç¨‹åºæ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {end_time - start_time:.2f} ç§’") 